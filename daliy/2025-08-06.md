关于水声 + 高频泛化：
- 可以类似 seq data, 讲连续频率的样本 叠起来成为序列样本
- 用 Sdift / shandian 类似的方法进行生成式建模，通过mask coding 进行生成
- 此类思路或可以用到类似多尺度场的建模中

关于 结构生成模型 中的 masked next-token prediction: 
 - uni-3dAR 中的mask 使用：原文： [Masked Next-Token Prediction ](https://zhuanlan.zhihu.com/p/1934584067929649982)
- 核心：对于 Transformer 中的 每个token，包含 （位置 $p_i$, 内容 $c_i$）
- 经典AR: $(p_i, c_i)_{i=1}^n --> c_{n+1}$, 
- 两种变形：
	- 位置完全未知，集合（点云）AR中，$(p_i, c_i)_{i=1}^n --> (p_{n+1},c_{n+1})$
	- 位置已知但动态变化（每个样本可能不一样）/ 乱序自回归 （字节的RAR）
		- $(p_i, c_i)_{i=1}^n + p_{n+1} --> (c_{n+1})$
		- 新思路：  Current-Token Prediction / 类似 MAR, 只关注 $p_{n+1} --> c_{n+1}$
		- 在AR 框架下：
			1. 对于原有的自回归序列，在每个 token 前面插入一个 Mask token；
			2. 将每个 token 的位置编码复制到对应（在它之前）的 Mask token；
			
			在这个复制后的序列上，再进行 Next-Token Prediction 的话，我们容易发现：

			3. Mask token 的“next-token” 恰好就是它自身的 Ground-truth ——相当于用自身的位置去预测自己的内容，模拟了 Masked Prediction；
			4. 同时，原始 token 依旧保留在序列中，保证了上文信息与经典 Next-Token Prediction 一致

- To check: RandAR （ insert a position instruction token）, MAR
	